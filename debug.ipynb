{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4442fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Tuple\n",
    "from app_v2_utils import normalize_model_display\n",
    "\n",
    "\n",
    "def split_model_variant(model_variant: str) -> Tuple[str, str]:\n",
    "    if not model_variant:\n",
    "        return \"\", \"\"\n",
    "\n",
    "    cleaned = model_variant.strip()\n",
    "\n",
    "    # Normalized model (e.g. \"I 20\" -> \"I20\")\n",
    "    model = normalize_model_display(cleaned).strip()\n",
    "\n",
    "    # Build a flexible regex: allow spaces between every character\n",
    "    # Example: \"I20\" -> \"I\\s*2\\s*0\"\n",
    "    spaced_pattern = r\"\\s*\".join(map(re.escape, model))\n",
    "\n",
    "    # Remove the model from the beginning OR anywhere in string\n",
    "    pattern = re.compile(rf\"^{spaced_pattern}[\\s\\-:–—]*\", re.IGNORECASE)\n",
    "\n",
    "    variant = pattern.sub(\"\", cleaned).strip()\n",
    "\n",
    "    return model, variant\n",
    "\n",
    "\n",
    "var = \"I 20 - ACTIVE S VTVT\"\n",
    "split_model_variant(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_v2_utils import normalize_make_display, normalize_model_display, split_model_variant, init_car_file_entry, merge_insurer_data_into_car_map, load_json_data\n",
    "from typing import Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "load_acko_data = load_json_data\n",
    "load_icici_data = load_json_data\n",
    "load_cholams_data = load_json_data\n",
    "load_royal_sundaram_data = load_json_data\n",
    "\n",
    "def scan_all_car_data() -> Dict[str, Any]:\n",
    "    \"\"\"Scan all data files and extract unique makes, models, and variants\"\"\"\n",
    "    extracted_dir = Path(\"extracted\")\n",
    "    car_data_map = {}\n",
    "    icici_data_list = []\n",
    "    cholams_data_list = []\n",
    "    royal_sundaram_data_list = []\n",
    "\n",
    "    acko_dir = extracted_dir / \"acko\"\n",
    "    if acko_dir.exists():\n",
    "        for file in acko_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                data = load_acko_data(str(file))\n",
    "            except Exception:\n",
    "                continue\n",
    "            car_info = data.get(\"car_info\", {})\n",
    "            make_raw = car_info.get(\"vehicle_make\", \"\").strip()\n",
    "            model_raw = car_info.get(\"vehicle_model\", \"\").strip()\n",
    "            variant = car_info.get(\"vehicle_variant\", \"\").strip()\n",
    "\n",
    "            make = normalize_make_display(make_raw)\n",
    "            model = normalize_model_display(model_raw)\n",
    "\n",
    "            print(\"acko\" + \" \" + f\"make: {make}, model: {model}, variant: {variant}\")\n",
    "\n",
    "            if make and model and variant:\n",
    "                key = (make, model, variant)\n",
    "                if key not in car_data_map:\n",
    "                    car_data_map[key] = init_car_file_entry()\n",
    "                car_data_map[key][\"acko\"].append(\n",
    "                    {\n",
    "                        \"file\": str(file),\n",
    "                        \"claim_status\": (\n",
    "                            file.stem.split(\"-\")[-1]\n",
    "                            if \"-\" in file.stem\n",
    "                            else \"not_claimed\"\n",
    "                        ),\n",
    "                        \"registration\": car_info.get(\"registration_number\", \"\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    icici_dir = extracted_dir / \"icici\"\n",
    "    if icici_dir.exists():\n",
    "        for file in icici_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                data = load_icici_data(str(file))\n",
    "            except Exception:\n",
    "                continue\n",
    "            make_raw = data.get(\"manufacturer\", \"\").strip()\n",
    "            model_raw = data.get(\"model\", \"\").strip()\n",
    "\n",
    "            make = normalize_make_display(make_raw)\n",
    "            model = normalize_model_display(model_raw)\n",
    "            _, variant = split_model_variant(model_raw)\n",
    "\n",
    "            print(\"icici\" + \" \" + f\"make: {make}, model: {model}, variant: {variant}\")\n",
    "\n",
    "            if make and model:\n",
    "                icici_data_list.append(\n",
    "                    {\n",
    "                        \"make\": make,\n",
    "                        \"model\": model,\n",
    "                        \"variant\": variant,\n",
    "                        \"file\": str(file),\n",
    "                        \"registration\": (\n",
    "                            file.stem.split(\"-\")[0] if \"-\" in file.stem else \"\"\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    cholams_dir = extracted_dir / \"cholams\"\n",
    "    if cholams_dir.exists():\n",
    "        for file in cholams_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                data = load_cholams_data(str(file))\n",
    "            except Exception:\n",
    "                continue\n",
    "            if isinstance(data, list) and len(data) > 0:\n",
    "                car_info = data[0] if isinstance(data[0], dict) else {}\n",
    "                make_raw = car_info.get(\"make\", \"\").strip()\n",
    "                model_raw = car_info.get(\"model\", \"\").strip()\n",
    "                variant_raw = car_info.get(\"variant\", \"\").strip()\n",
    "\n",
    "                make = normalize_make_display(make_raw)\n",
    "                model = normalize_model_display(model_raw)\n",
    "                _ , variant = split_model_variant(variant_raw)\n",
    "                print(\n",
    "                    \"cholams\"\n",
    "                    + \" \"\n",
    "                    + f\"make: {make}, model: {model}, variant: {variant}\"\n",
    "                )\n",
    "\n",
    "                if make and model:\n",
    "                    cholams_data_list.append(\n",
    "                        {\n",
    "                            \"make\": make,\n",
    "                            \"model\": model,\n",
    "                            \"variant\": variant,\n",
    "                            \"file\": str(file),\n",
    "                            \"registration\": car_info.get(\"registration_number\", \"\"),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    royal_sundaram_dir = extracted_dir / \"royal_sundaram\"\n",
    "    if royal_sundaram_dir.exists():\n",
    "        for file in royal_sundaram_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                data = load_royal_sundaram_data(str(file))\n",
    "            except Exception:\n",
    "                continue\n",
    "            car_details = data.get(\"car_details\", {}) or {}\n",
    "            make_raw = car_details.get(\"manufacturer\", \"\").strip()\n",
    "            model_variant_raw = car_details.get(\"model_variant\", \"\").strip()\n",
    "            model_part, variant_part = split_model_variant(model_variant_raw)\n",
    "\n",
    "            make = normalize_make_display(make_raw)\n",
    "            model = normalize_model_display(model_part)\n",
    "            variant = variant_part\n",
    "\n",
    "            print(\n",
    "                \"royal_sundaram\"\n",
    "                + \" \"\n",
    "                + f\"make: {make}, model: {model}, variant: {variant}\"\n",
    "            )\n",
    "\n",
    "            if make and model:\n",
    "                royal_sundaram_data_list.append(\n",
    "                    {\n",
    "                        \"make\": make,\n",
    "                        \"model\": model,\n",
    "                        \"variant\": variant,\n",
    "                        \"file\": str(file),\n",
    "                        \"registration\": car_details.get(\"registration_number\", \"\"),\n",
    "                        \"claim_status\": (\n",
    "                            file.stem.split(\"-\")[-1] if \"-\" in file.stem else \"\"\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    merge_insurer_data_into_car_map(\n",
    "        car_data_map,\n",
    "        icici_data_list,\n",
    "        \"icici\",\n",
    "        [\"file\", \"registration\"],\n",
    "    )\n",
    "    merge_insurer_data_into_car_map(\n",
    "        car_data_map,\n",
    "        cholams_data_list,\n",
    "        \"cholams\",\n",
    "        [\"file\", \"registration\"],\n",
    "    )\n",
    "    merge_insurer_data_into_car_map(\n",
    "        car_data_map,\n",
    "        royal_sundaram_data_list,\n",
    "        \"royal_sundaram\",\n",
    "        [\"file\", \"registration\"],\n",
    "        extra_fields_func=lambda entry: {\"claim_status\": entry[\"claim_status\"]},\n",
    "    )\n",
    "\n",
    "    return car_data_map\n",
    "\n",
    "scan_all_car_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
